<!DOCTYPE html>
<html lang="en">
<head>
    <title>A Tour of PyTorch Internals (Part I)</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:200,300,400,600,700">
    <link rel="stylesheet" 
        href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" 
        integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" 
        crossorigin="anonymous">
    <link rel="stylesheet" href="/static/css/main.css">
</head>
<body id="/2017/05/11/Internals">

    <header>

    
    <div class="container">
    

    <div class="logo"><a href="/"></a></div>


    <a class="btn" href="/docs/">ANTsPy Docs</a>
    <a class="btn" href="https://www.rdocumentation.org/packages/ANTsR/versions/1.0">ANTsR Docs</a>
    <a class="btn" href="http://stnava.github.io/ANTs/">ANTs Docs</a>

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>


    <ul class="primary-nav"">
    
    <li><a  href="/">Get Started</a></li>
    <li><a  href="/about/">About</a></li>

    <li class="dropdown">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Research<span class="caret"></span></a>
      <ul class="dropdown-menu">
        <li><a href="/literature/">Literature</a></li>
        <li><a href="#">Case Studies</a></li>
        <li><a href="#">Tutorials</a></li>
      </ul>
    </li>

    <li><a  href="https://discuss.pytorch.org">Discuss</a></li>
</ul>


    
    </div>
    

</header>

    <section class="content wrap">
	<div class="container">

	    <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

	      <section class="post-header">
		<h1 class="post-title" itemprop="name headline">A Tour of PyTorch Internals (Part I)</h1>
		<p class="post-meta">
		  <time datetime="2017-05-11T10:00:00-07:00" itemprop="datePublished">
		    
		    May 11, 2017
		  </time>
		  
		    • <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">Trevor Killeen</span></span>
		  </p>
	      </section>

	      <div class="post-content" itemprop="articleBody">
		<p>The fundamental unit in PyTorch is the Tensor. This post will serve as an overview for how we implement Tensors in PyTorch, such that the user can interact with it from the Python shell. In particular, we want to answer four main questions:</p>

<ul>
  <li>How does PyTorch extend the Python interpreter to define a Tensor type that can be manipulated from Python code?</li>
  <li>How does PyTorch wrap the C libraries that actually define the Tensor’s properties and methods?</li>
  <li>How does PyTorch cwrap work to generate code for Tensor methods?</li>
  <li>How does PyTorch’s build system take all of these components to compile and generate a workable application?</li>
</ul>

<h2 id="extending-the-python-interpreter">Extending the Python Interpreter</h2>
<hr />

<p>PyTorch defines a new package <code class="highlighter-rouge">torch</code>. In this post we will consider the <code class="highlighter-rouge">._C</code> module. This module is known as an “extension module” - a Python module written in C. Such modules allow us to define new built-in object types (e.g. the <code class="highlighter-rouge">Tensor</code>) and to call C/C++ functions.</p>

<p>The <code class="highlighter-rouge">._C</code> module is defined in <code class="highlighter-rouge">torch/csrc/Module.cpp</code>. The <code class="highlighter-rouge">init_C()</code> / <code class="highlighter-rouge">PyInit__C()</code> function creates the module and adds the method definitions as appropriate. This module is passed around to a number of different <code class="highlighter-rouge">__init()</code> functions that add further objects to the module, register new types, etc.</p>

<p>One collection of these <code class="highlighter-rouge">__init()</code> calls is the following:</p>

<div class="language-cpp highlighter-rouge"><pre class="highlight"><code><span class="n">ASSERT_TRUE</span><span class="p">(</span><span class="n">THPDoubleTensor_init</span><span class="p">(</span><span class="n">module</span><span class="p">));</span>
<span class="n">ASSERT_TRUE</span><span class="p">(</span><span class="n">THPFloatTensor_init</span><span class="p">(</span><span class="n">module</span><span class="p">));</span>
<span class="n">ASSERT_TRUE</span><span class="p">(</span><span class="n">THPHalfTensor_init</span><span class="p">(</span><span class="n">module</span><span class="p">));</span>
<span class="n">ASSERT_TRUE</span><span class="p">(</span><span class="n">THPLongTensor_init</span><span class="p">(</span><span class="n">module</span><span class="p">));</span>
<span class="n">ASSERT_TRUE</span><span class="p">(</span><span class="n">THPIntTensor_init</span><span class="p">(</span><span class="n">module</span><span class="p">));</span>
<span class="n">ASSERT_TRUE</span><span class="p">(</span><span class="n">THPShortTensor_init</span><span class="p">(</span><span class="n">module</span><span class="p">));</span>
<span class="n">ASSERT_TRUE</span><span class="p">(</span><span class="n">THPCharTensor_init</span><span class="p">(</span><span class="n">module</span><span class="p">));</span>
<span class="n">ASSERT_TRUE</span><span class="p">(</span><span class="n">THPByteTensor_init</span><span class="p">(</span><span class="n">module</span><span class="p">));</span>
</code></pre>
</div>

<p>These <code class="highlighter-rouge">__init()</code> functions add the Tensor object for each type to the <code class="highlighter-rouge">._C</code> module so that they can be used in the module. Let’s learn how these methods work.</p>

<h2 id="the-thptensor-type">The THPTensor Type</h2>
<hr />

<p>Much like the underlying <code class="highlighter-rouge">TH</code> and <code class="highlighter-rouge">THC</code> libraries, PyTorch defines a “generic” Tensor which is then specialized to a number of different types. Before considering how this specialization works, let’s first consider how defining a new type in Python works, and how we create the generic <code class="highlighter-rouge">THPTensor</code> type.</p>

<p>The Python runtime sees all Python objects as variables of type <code class="highlighter-rouge">PyObject *</code>, which serves as a “base type” for all Python objects. Every Python type contains the refcount for the object, and a pointer to the object’s <em>type object</em>. The type object determines the properties of the type. For example, it might contain a list of methods associated with the type, and which C functions get called to implement those methods. The object also contains any fields necessary to represent its state.</p>

<p>The formula for defining a new type is as follows:</p>

<ul>
  <li>Create a struct that defines what the new object will contain</li>
  <li>Define the type object for the type</li>
</ul>

<p>The struct itself could be very simple. Inn Python, all floating point types are actually objects on the heap. The Python float struct is defined as:</p>
<div class="language-cpp highlighter-rouge"><pre class="highlight"><code><span class="k">typedef</span> <span class="k">struct</span> <span class="p">{</span>
    <span class="n">PyObject_HEAD</span>
    <span class="kt">double</span> <span class="n">ob_fval</span><span class="p">;</span>
<span class="p">}</span> <span class="n">PyFloatObject</span><span class="p">;</span>
</code></pre>
</div>
<p>The <code class="highlighter-rouge">PyObject_HEAD</code> is a macro that brings in the code that implements an object’s reference counting, and a pointer to the corresponding type object. So in this case, to implement a float, the only other “state” needed is the floating point value itself.</p>

<p>Now, let’s see the struct for our <code class="highlighter-rouge">THPTensor</code> type:</p>
<div class="highlighter-rouge"><pre class="highlight"><code>struct THPTensor {
    PyObject_HEAD
    THTensor *cdata;
};
</code></pre>
</div>
<p>Pretty simple, right? We are just wrapping the underlying <code class="highlighter-rouge">TH</code> tensor by storing a pointer to it.</p>

<p>The key part is defining the “type object” for a new type. An example definition of a type object for our Python float takes the form:</p>
<div class="highlighter-rouge"><pre class="highlight"><code>static PyTypeObject py_FloatType = {
    PyVarObject_HEAD_INIT(NULL, 0)
    "py.FloatObject",          /* tp_name */
    sizeof(PyFloatObject),     /* tp_basicsize */
    0,                         /* tp_itemsize */
    0,                         /* tp_dealloc */
    0,                         /* tp_print */
    0,                         /* tp_getattr */
    0,                         /* tp_setattr */
    0,                         /* tp_as_async */
    0,                         /* tp_repr */
    0,                         /* tp_as_number */
    0,                         /* tp_as_sequence */
    0,                         /* tp_as_mapping */
    0,                         /* tp_hash  */
    0,                         /* tp_call */
    0,                         /* tp_str */
    0,                         /* tp_getattro */
    0,                         /* tp_setattro */
    0,                         /* tp_as_buffer */
    Py_TPFLAGS_DEFAULT,        /* tp_flags */
    "A floating point number", /* tp_doc */
};
</code></pre>
</div>
<p>The easiest way to think of a <em>type object</em> is as a set of fields which define the properties of the object. For example, the <code class="highlighter-rouge">tp_basicsize</code> field is set to <code class="highlighter-rouge">sizeof(PyFloatObject)</code>. This is so that Python knows how much memory to allocate when calling <code class="highlighter-rouge">PyObject_New()</code> for a <code class="highlighter-rouge">PyFloatObject.</code> The full list of fields you can set is defined in <code class="highlighter-rouge">object.h</code> in the CPython backend:
https://github.com/python/cpython/blob/master/Include/object.h.</p>

<p>The type object for our <code class="highlighter-rouge">THPTensor</code> is <code class="highlighter-rouge">THPTensorType</code>, defined in <code class="highlighter-rouge">csrc/generic/Tensor.cpp</code>. This object defines the name, size, mapping methods, etc. for a <code class="highlighter-rouge">THPTensor</code>.</p>

<p>As an example, let’s take a look at the <code class="highlighter-rouge">tp_new</code> function we set in the <code class="highlighter-rouge">PyTypeObject</code>:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>PyTypeObject THPTensorType = {
  PyVarObject_HEAD_INIT(NULL, 0)
  ...
  THPTensor_(pynew), /* tp_new */
};
</code></pre>
</div>
<p>The <code class="highlighter-rouge">tp_new</code> function enables object creation. It is responsible for creating (as opposed to initializing) objects of that type and is equivalent to the <code class="highlighter-rouge">__new()__</code> method at the Python level. The C implementation is a static method that is passed the type being instantiated and any arguments, and returns a newly created object.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>static PyObject * THPTensor_(pynew)(PyTypeObject *type, PyObject *args, PyObject *kwargs)
{
  HANDLE_TH_ERRORS
  Py_ssize_t num_args = args ? PyTuple_Size(args) : 0;

  THPTensorPtr self = (THPTensor *)type-&gt;tp_alloc(type, 0);
// more code below
</code></pre>
</div>
<p>The first thing our new function does is allocate the <code class="highlighter-rouge">THPTensor</code>. It then runs through a series of initializations based off of the args passed to the function. For example, when creating a <code class="highlighter-rouge">THPTensor</code> <em>x</em> from another <code class="highlighter-rouge">THPTensor</code> <em>y</em>, we set the newly created <code class="highlighter-rouge">THPTensor</code>’s <code class="highlighter-rouge">cdata</code> field to be the result of calling <code class="highlighter-rouge">THTensor_(newWithTensor)</code> with the <em>y</em>’s underlying <code class="highlighter-rouge">TH</code> Tensor as an argument. Similar constructors exist for sizes, storages, NumPy arrays, and sequences.</p>

<p>** Note that we solely use <code class="highlighter-rouge">tp_new</code>, and not a combination of <code class="highlighter-rouge">tp_new</code> and <code class="highlighter-rouge">tp_init</code> (which corresponds to the <code class="highlighter-rouge">__init()__</code> function).</p>

<p>The other important thing defined in Tensor.cpp is how indexing works. PyTorch Tensors support Python’s <strong>Mapping Protocol</strong>. This allows us to do things like:</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">//</span> <span class="n">y</span> <span class="o">==</span> <span class="mi">1</span>
<span class="n">x</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>
<span class="o">//</span> <span class="n">etc</span><span class="o">.</span>
</code></pre>
</div>
<p>** Note that this indexing extends to Tensor with more than one dimension</p>

<p>We are able to use the <code class="highlighter-rouge">[]</code>-style notation by defining the three mapping methods described <a href="https://docs.python.org/3.7/c-api/typeobj.html#c.PyMappingMethods">here.</a></p>

<p>The most important methods are <code class="highlighter-rouge">THPTensor_(getValue)</code> and <code class="highlighter-rouge">THPTensor_(setValue)</code> which describe how to index a Tensor, for returning a new Tensor/Scalar, or updating the values of an existing Tensor in place. Read through these implementations to better understand how PyTorch supports basic tensor indexing.</p>

<h3 id="generic-builds-part-one">Generic Builds (Part One)</h3>
<hr />

<p>We could spend a ton of time exploring various aspects of the <code class="highlighter-rouge">THPTensor</code> and how it relates to defining a new Python object. But we still need to see how the <code class="highlighter-rouge">THPTensor_(init)()</code> function is translated to the <code class="highlighter-rouge">THPIntTensor_init()</code> we used in our module initialization. How do we take our <code class="highlighter-rouge">Tensor.cpp</code> file that defines a “generic” Tensor and use it to generate Python objects for all the permutations of types? To put it another way, <code class="highlighter-rouge">Tensor.cpp</code> is littered with lines of code like:</p>
<div class="highlighter-rouge"><pre class="highlight"><code>return THPTensor_(New)(THTensor_(new)(LIBRARY_STATE_NOARGS));
</code></pre>
</div>
<p>This illustrates both cases we need to make type-specific:</p>

<ul>
  <li>Our output code will call <code class="highlighter-rouge">THP&lt;Type&gt;Tensor_New(...)</code> in place of <code class="highlighter-rouge">THPTensor_(New)</code></li>
  <li>Our output code will call <code class="highlighter-rouge">TH&lt;Type&gt;Tensor_new(...)</code> in place of <code class="highlighter-rouge">THTensor_(new)</code></li>
</ul>

<p>In other words, for all supported Tensor types, we need to “generate” source code that has done the above substitutions. This is part of the “build” process for PyTorch. PyTorch relies on Setuptools (https://setuptools.readthedocs.io/en/latest/) for building the package, and we define a <code class="highlighter-rouge">setup.py</code> file in the top-level directory to customize the build process.</p>

<p>One component building an Extension module using Setuptools is to list the source files involved in the compilation. However, our <code class="highlighter-rouge">csrc/generic/Tensor.cpp</code> file is not listed! So how does the code in this file end up being a part of the end product?</p>

<p>Recall that we are calling the <code class="highlighter-rouge">THPTensor*</code> functions (such as <code class="highlighter-rouge">init</code>) from the directory above <code class="highlighter-rouge">generic</code>. If we take a look in this directory, there is another file <code class="highlighter-rouge">Tensor.cpp</code> defined. The last line of this file is important:</p>
<div class="highlighter-rouge"><pre class="highlight"><code>//generic_include TH torch/csrc/generic/Tensor.cpp
</code></pre>
</div>
<p>Note that this <code class="highlighter-rouge">Tensor.cpp</code> file is included in <code class="highlighter-rouge">setup.py</code>, but it is wrapped in a call to a Python helper function called <code class="highlighter-rouge">split_types</code>. This function takes as input a file, and looks for the “//generic_include” string in the file contents. If it is found, it generates a new output file for each Tensor type, with the following changes:</p>

<ul>
  <li>The output file is renamed to <code class="highlighter-rouge">Tensor&lt;Type&gt;.cpp</code></li>
  <li>The output file is slightly modified as follows:</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code># Before:
//generic_include TH torch/csrc/generic/Tensor.cpp

# After:
#define TH_GENERIC_FILE "torch/src/generic/Tensor.cpp"
#include "TH/THGenerate&lt;Type&gt;Type.h"
</code></pre>
</div>
<p>Including the header file on the second line has the side effect of including the source code in <code class="highlighter-rouge">Tensor.cpp</code> with some additional context defined. Let’s take a look at one of the headers:</p>
<div class="highlighter-rouge"><pre class="highlight"><code>#ifndef TH_GENERIC_FILE
#error "You must define TH_GENERIC_FILE before including THGenerateFloatType.h"
#endif

#define real float
#define accreal double
#define TH_CONVERT_REAL_TO_ACCREAL(_val) (accreal)(_val)
#define TH_CONVERT_ACCREAL_TO_REAL(_val) (real)(_val)
#define Real Float
#define THInf FLT_MAX
#define TH_REAL_IS_FLOAT
#line 1 TH_GENERIC_FILE
#include TH_GENERIC_FILE
#undef accreal
#undef real
#undef Real
#undef THInf
#undef TH_REAL_IS_FLOAT
#undef TH_CONVERT_REAL_TO_ACCREAL
#undef TH_CONVERT_ACCREAL_TO_REAL

#ifndef THGenerateManyTypes
#undef TH_GENERIC_FILE
#endif
</code></pre>
</div>
<p>What this is doing is bringing in the code from the generic <code class="highlighter-rouge">Tensor.cpp</code> file and surrounding it with the following macro definitions. For example, we define real as a float, so any code in the generic Tensor implementation that refers to something as a real will have that real replaced with a float. In the corresponding file <code class="highlighter-rouge">THGenerateIntType.h</code>, the same macro would replace <code class="highlighter-rouge">real</code> with <code class="highlighter-rouge">int</code>.</p>

<p>These output files are returned from <code class="highlighter-rouge">split_types</code> and added to the list of source files, so we can see how the <code class="highlighter-rouge">.cpp</code> code for different types is created.</p>

<p>There are a few things to note here: First, the <code class="highlighter-rouge">split_types</code> function is not strictly necessary. We could wrap the code in <code class="highlighter-rouge">Tensor.cpp</code> in a single file, repeating it for each type. The reason we split the code into separate files is to speed up compilation. Second, what we mean when we talk about the type replacement (e.g. replace real with a float) is that the C preprocessor will perform these subsitutions during compilaiton. Merely surrounding the source code with these macros has no side effects until preprocessing.</p>

<h3 id="generic-builds-part-two">Generic Builds (Part Two)</h3>
<hr />

<p>Now that we have source files for all the Tensor types, we need to consider how the corresponding header declarations are created, and also how the conversions from <code class="highlighter-rouge">THTensor_(method)</code> and <code class="highlighter-rouge">THPTensor_(method)</code> to <code class="highlighter-rouge">TH&lt;Type&gt;Tensor_method</code> and <code class="highlighter-rouge">THP&lt;Type&gt;Tensor_method</code> work. For example, <code class="highlighter-rouge">csrc/generic/Tensor.h</code> has declarations like:</p>
<div class="highlighter-rouge"><pre class="highlight"><code>THP_API PyObject * THPTensor_(New)(THTensor *ptr);
</code></pre>
</div>
<p>We use the same strategy for generating code in the source files for the headers. In <code class="highlighter-rouge">csrc/Tensor.h</code>, we do the following:</p>
<div class="highlighter-rouge"><pre class="highlight"><code>#include "generic/Tensor.h"
#include &lt;TH/THGenerateAllTypes.h&gt;

#include "generic/Tensor.h"
#include &lt;TH/THGenerateHalfType.h&gt;
</code></pre>
</div>
<p>This has the same effect, where we draw in the code from the generic header, wrapped with the same macro definitions, for each type. The only difference is that the resulting code is contained all within the same header file, as opposed to being split into multiple source files.</p>

<p>Lastly, we need to consider how we “convert” or “substitute” the function types. If we look in the same header file, we see a bunch of <code class="highlighter-rouge">#define</code> statements, including:</p>
<div class="highlighter-rouge"><pre class="highlight"><code>#define THPTensor_(NAME)            TH_CONCAT_4(THP,Real,Tensor_,NAME)
</code></pre>
</div>
<p>This macro says that any string in the source code matching the format <code class="highlighter-rouge">THPTensor_(NAME)</code> should be replaced with <code class="highlighter-rouge">THPRealTensor_NAME</code>, where Real is derived from whatever the symbol Real is <code class="highlighter-rouge">#define</code>‘d to be at the time. Because our header code and source code is surrounded by macro definitions for all the types as seen above, after the preprocessor has run, the resulting code is what we would expect. The code in the <code class="highlighter-rouge">TH</code> library defines the same macro for <code class="highlighter-rouge">THTensor_(NAME)</code>, supporting the translation of those functions as well. In this way, we end up with header and source files with specialized code.
####Module Objects and Type Methods
Now we have seen how we have wrapped <code class="highlighter-rouge">TH</code>’s Tensor definition in <code class="highlighter-rouge">THP</code>, and generated THP methods such as <code class="highlighter-rouge">THPFloatTensor_init(...)</code>. Now we can explore what the above code actually does in terms of the module we are creating. The key line in <code class="highlighter-rouge">THPTensor_(init)</code> is:</p>
<div class="highlighter-rouge"><pre class="highlight"><code># THPTensorBaseStr, THPTensorType are also macros that are specific 
# to each type
PyModule_AddObject(module, THPTensorBaseStr, (PyObject *)&amp;THPTensorType);
</code></pre>
</div>
<p>This function registers our Tensor objects to the extension module, so we can use THPFloatTensor, THPIntTensor, etc. in our Python code.</p>

<p>Just being able to create Tensors isn’t very useful - we need to be able to call all the methods that <code class="highlighter-rouge">TH</code> defines. A simple example shows calling the in-place <code class="highlighter-rouge">zero_</code> method on a Tensor.</p>
<div class="highlighter-rouge"><pre class="highlight"><code>x = torch.FloatTensor(10)
x.zero_()
</code></pre>
</div>
<p>Let’s start by seeing how we add methods to newly defined types. One of the fields in the “type object” is <code class="highlighter-rouge">tp_methods</code>. This field holds an array of method definitions (<code class="highlighter-rouge">PyMethodDef</code>s) and is used to associate methods (and their underlying C/C++ implementations) with a type. Suppose we wanted to define a new method on our <code class="highlighter-rouge">PyFloatObject</code> that replaces the value. We could implement this as follows:</p>
<div class="highlighter-rouge"><pre class="highlight"><code>static PyObject * replace(PyFloatObject *self, PyObject *args) {
	double val;
	if (!PyArg_ParseTuple(args, "d", &amp;val))
		return NULL;
	self-&gt;ob_fval = val;
	Py_RETURN_NONE
}
</code></pre>
</div>
<p>This is equivalent to the Python method:</p>
<div class="highlighter-rouge"><pre class="highlight"><code>def replace(self, val):
	self.ob_fval = fal
</code></pre>
</div>
<p>It is instructive to read more about how defining methods works in CPython. In general, methods take as the first parameter the instance of the object, and optionally parameters for the positional arguments and keyword arguments. This static function is registered as a method on our float:</p>
<div class="highlighter-rouge"><pre class="highlight"><code>static PyMethodDef float_methods[] = {
	{"replace", (PyCFunction)replace, METH_VARARGS,
	"replace the value in the float"
	},
	{NULL} /* Sentinel */
}
</code></pre>
</div>
<p>This registers a method called replace, which is implemented by the C function of the same name. The <code class="highlighter-rouge">METH_VARARGS</code> flag indicates that the method takes a tuple of arguments representing all the arguments to the function. This array is set to the <code class="highlighter-rouge">tp_methods</code> field of the type object, and then we can use the <code class="highlighter-rouge">replace</code> method on objects of that type.</p>

<p>We would like to be able to call all of the methods for <code class="highlighter-rouge">TH</code> tensors on our <code class="highlighter-rouge">THP</code> tensor equivalents. However, writing wrappers for all of the <code class="highlighter-rouge">TH</code> methods would be time-consuming and error prone. We need a better way to do this.</p>
<h3 id="pytorch-cwrap">PyTorch cwrap</h3>
<hr />
<p>PyTorch implements its own cwrap tool to wrap the <code class="highlighter-rouge">TH</code> Tensor methods for use in the Python backend. We define a <code class="highlighter-rouge">.cwrap</code> file containing a series of C method declarations in our custom YAML format (http://yaml.org). The cwrap tool takes this file and outputs <code class="highlighter-rouge">.cpp</code> source files containing the wrapped methods in a format that is compatible with our <code class="highlighter-rouge">THPTensor</code> Python object and the Python C extension method calling format. This tool is used to generate code to wrap not only <code class="highlighter-rouge">TH</code>, but also <code class="highlighter-rouge">CuDNN</code>. It is defined to be extensible.</p>

<p>An example YAML “declaration” for the in-place <code class="highlighter-rouge">addmv_</code> function is as follows:</p>
<div class="highlighter-rouge"><pre class="highlight"><code>[[
  name: addmv_
  cname: addmv
  return: self
  arguments:
    - THTensor* self
    - arg: real beta
      default: AS_REAL(1)
    - THTensor* self
    - arg: real alpha
      default: AS_REAL(1)
    - THTensor* mat
    - THTensor* vec
]]
</code></pre>
</div>
<p>The architecture of the cwrap tool is very simple. It reads in a file, and then processes it with a series of <strong>plugins.</strong> See <code class="highlighter-rouge">tools/cwrap/plugins/__init__.py</code> for documentation on all the ways a plugin can alter the code.</p>

<p>The source code generation occurs in a series of passes. First, the YAML “declaration” is parsed and processed. Then the source code is generated piece-by-piece - adding things like argument checks and extractions, defining the method header, and the actual call to the underlying library such as <code class="highlighter-rouge">TH</code>. Finally, the cwrap tool allows for processing the entire file at a time. The resulting output for <code class="highlighter-rouge">addmv_</code> can be explored here: https://gist.github.com/killeent/c00de46c2a896335a52552604cc4d74b.</p>

<p>In order to interface with the CPython backend, the tool generates an array of <code class="highlighter-rouge">PyMethodDef</code>s that can be stored or appended to the <code class="highlighter-rouge">THPTensor</code>’s <code class="highlighter-rouge">tp_methods</code> field.</p>

<p>In the specific case of wrapping Tensor methods, the build process first generates the output source file from <code class="highlighter-rouge">TensorMethods.cwrap</code>. This source file is <code class="highlighter-rouge">#include</code>‘d in the generic Tensor source file. This all occurs before the preprocessor does its magic. As a result, all of the method wrappers that are generated undergo the same pass as the <code class="highlighter-rouge">THPTensor</code> code above. Thus a single generic declaration and definition is specialized for each type as well.</p>

<h3 id="putting-it-all-together">Putting It All Together</h3>
<hr />

<p>So far, we have shown how we extend the Python interpreter to create a new extension module, how such a module defines our new <code class="highlighter-rouge">THPTensor</code> type, and how we can generate source code for Tensors of all types that interface with <code class="highlighter-rouge">TH</code>. Briefly, we will touch on compilation.</p>

<p>Setuptools allows us to define an Extension for compilation. The entire <code class="highlighter-rouge">torch._C</code> extension is compiled by collecting all of the source files, header files, libraries, etc. and creating a setuptools <code class="highlighter-rouge">Extension</code>. Then setuptools handles building the extension itself. I will explore the build process more in a subsequent post.</p>

<p>To summarize, let’s revisit our four questions:</p>

<ul>
  <li><strong>How does PyTorch extend the Python interpreter to define a Tensor type that can be manipulated from Python code?</strong></li>
</ul>

<p>It uses CPython’s framework for extending the Python interpreter and defining new types, while taking special care to generate code for all types.</p>

<ul>
  <li><strong>How does PyTorch wrap the C libraries that actually define the Tensor’s properties and methods?</strong></li>
</ul>

<p>It does so by defining a new type, <code class="highlighter-rouge">THPTensor</code>, that is backed by a <code class="highlighter-rouge">TH</code> Tensor. Function calls are forwarded to this tensor via the CPython backend’s conventions.</p>

<ul>
  <li><strong>How does PyTorch cwrap work to generate code for Tensor methods?</strong></li>
</ul>

<p>It takes our custom YAML-formatted code and generates source code for each method by processing it through a series of steps using a number of plugins.</p>

<ul>
  <li><strong>How does PyTorch’s build system take all of these components to compile and generate a workable application?</strong></li>
</ul>

<p>It takes a bunch of source/header files, libraries, and compilation directives to build an extension using Setuptools.</p>

<hr />

<p>This is just a snapshot of parts of the build system for PyTorch. There is more nuance, and detail, but I hope this serves as a gentle introduction to a lot of the components of our Tensor library.</p>

<h3 id="resources">Resources:</h3>
<hr />

<ul>
  <li>https://docs.python.org/3.7/extending/index.html is invaluable for understanding how to write C/C++ Extension to Python</li>
</ul>

	      </div>

	      
	    </article>

        </div>
    </section>

    <footer>

    
    <div class="container">
    

    <div class="left">
        <div style="height: 30px" class="logo"><a  href="/"></a></div>
        <p>
            Maintained by the ANTs consortium. <br>
            &copy;2017 ANTs
        </p>
    </div>
    
    <ul class="primary-nav"">
    
    <li><a  href="/">Get Started</a></li>
    <li><a  href="/about/">About</a></li>

    <li class="dropdown">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Research<span class="caret"></span></a>
      <ul class="dropdown-menu">
        <li><a href="/literature/">Literature</a></li>
        <li><a href="#">Case Studies</a></li>
        <li><a href="#">Tutorials</a></li>
      </ul>
    </li>

    <li><a  href="https://discuss.pytorch.org">Discuss</a></li>
</ul>


    
    </div>
    

</footer>


</body>
</html>
